{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F1KtL4Kpcxn"
   },
   "source": [
    "# Data Science - Assignment 4 - Collaborative Filtering\n",
    "\n",
    "Thomas Br√ºndl\n",
    "\n",
    "se21m032\n",
    "\n",
    "Dataset: <b>MovieLens</b>\n",
    "\n",
    "1. 100k Dataset: https://grouplens.org/datasets/movielens/100k/\n",
    "2. 1M Dataset:  https://grouplens.org/datasets/movielens/1m/\n",
    "\n",
    "\n",
    "\n",
    "## Approach\n",
    "\n",
    "In this exercise I investigated the `Effectiveness` and `Efficiency` of six collaborative filtering techniques:\n",
    "\n",
    "1. User based filtering (memory CF)\n",
    "2. Item based filtering (memory CF)\n",
    "3. SVD (model CF)\n",
    "4. KNNBasic (model CF)\n",
    "5. CoClustering (model CF)\n",
    "6. KNNBaseline (model CF)\n",
    "\n",
    "\n",
    "## Measurement\n",
    "\n",
    "The Effectiveness of a collaborative filtering approach was measured by terms of MSE (mean squared error) between the predicted score and the actual score known in the test set.\n",
    "\n",
    "The Efficiency of a collaborative filtering approach was measured by runtime (i.e. how long the program took to finish). \n",
    "\n",
    "## Data\n",
    "\n",
    "The data consists of a small data set with 100K samples and a large data set with 1M samples.\n",
    "The samples can be described by four attributes:\n",
    "\n",
    "1. userId\n",
    "2. movieId\n",
    "3. rating\n",
    "4. timestamp\n",
    "\n",
    "## Disclaimer\n",
    "\n",
    "Some code snippets where taken from the repository of `sharmin2697`.\n",
    "\n",
    "https://github.com/sharmin2697/Movie-Recommender-System\n",
    "\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "\n",
    "User-based-CF is faster (more efficient) than item-based-CF when performing the test with the 100K and 1M dataset.\n",
    "However, item-based-CF produces less MSE (more effective) than the user-based-CF.\n",
    "\n",
    "SVD seems to outperform all other approaches by far in terms of effectiveness and efficiency.\n",
    "\n",
    "The MSE could be decreased in all approaches by using the large data set with 1M instead of the small data set of 100K.\n",
    "\n",
    "<br>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th></th>\n",
    "<th colspan=\"6\">100K Dataset</th>\n",
    "\n",
    " <tr>\n",
    "<tr>\n",
    "<th></th>\n",
    "<th colspan=\"2\">Memory Based</th>\n",
    "<th colspan=\"4\">Model Based</th>\n",
    " <tr>\n",
    "  <tr>\n",
    "  <th></th>\n",
    "    <th>user_based_CF</th>\n",
    "    <th>item_based_CF</th>\n",
    "    <th>SVD</th>\n",
    "    <th>KNNBasic</th>\n",
    "    <th>CoClustering</th>\n",
    "    <th>KNNBaseline</th>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "  <td><b>mse</b></td>\n",
    "    <td>0.903</td>\n",
    "    <td>0.875</td>\n",
    "    <td>0.865</td>\n",
    "    <td>0.907</td>\n",
    "    <td>0.912</td>\n",
    "    <td>0.898</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td><b>time [sec]</b></td>\n",
    "    <td>24.43</td>\n",
    "    <td>30.07</td>\n",
    "    <td>18.929</td>\n",
    "    <td>33.444</td>\n",
    "    <td>43.649</td>\n",
    "    <td>62.218</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th></th>\n",
    "<th colspan=\"6\">1M Dataset</th>\n",
    "\n",
    " <tr>\n",
    "<tr>\n",
    "<th></th>\n",
    "<th colspan=\"2\">Memory Based</th>\n",
    "<th colspan=\"4\">Model Based</th>\n",
    " <tr>\n",
    "  <tr>\n",
    "  <th></th>\n",
    "    <th>user_based_CF</th>\n",
    "    <th>item_based_CF</th>\n",
    "    <th>SVD</th>\n",
    "    <th>KNNBasic</th>\n",
    "    <th>CoClustering</th>\n",
    "    <th>KNNBaseline</th>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "  <td><b>mse</b></td>\n",
    "    <td>0.864</td>\n",
    "    <td>0.813</td>\n",
    "    <td>0.763</td>\n",
    "    <td>0.807</td>\n",
    "    <td>0.817</td>\n",
    "    <td>0.813</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td><b>time [sec]</b></td>\n",
    "    <td>916.553</td>\n",
    "    <td>1957.769</td>\n",
    "    <td>171.219</td>\n",
    "    <td>1221.513</td>\n",
    "    <td>1317.121</td>\n",
    "    <td>1957.769</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9hCjS52v8re"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AEDn0V48mUaY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import statistics\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVD\n",
    "from surprise import CoClustering\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrU296jSv2Bb"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "jis3xMm7vkWI",
    "outputId": "cadc2b43-9584-41dc-d792-e15b7f7518dd"
   },
   "outputs": [],
   "source": [
    "# ratings = pd.read_csv('ratings_100K.csv')\n",
    "ratings = pd.read_csv('ratings_1M.csv')\n",
    "ratings = ratings.drop([\"timestamp\"], axis=1)\n",
    "data = ratings\n",
    "data.head()\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "rating_dataset = Dataset.load_from_df(data, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_datasets = []\n",
    "\n",
    "rating_datasets.append(train_test_split(rating_dataset, test_size=0.2, random_state=1524401))\n",
    "rating_datasets.append(train_test_split(rating_dataset, test_size=0.2))\n",
    "rating_datasets.append(train_test_split(rating_dataset, test_size=0.2))\n",
    "rating_datasets.append(train_test_split(rating_dataset, test_size=0.2))\n",
    "rating_datasets.append(train_test_split(rating_dataset, test_size=0.2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8651\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8634\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8605\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8662\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8658\n",
      "Time: 941.383880853653\n",
      "Mean mse: 0.8641993653203587\n"
     ]
    }
   ],
   "source": [
    "mse_results = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for (trainset, testset) in rating_datasets:\n",
    "    algo = KNNWithMeans(100, 1, {'name': 'cosine','user_based': True})\n",
    "\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    mse = accuracy.mse(predictions)\n",
    "    mse_results.append(mse)\n",
    "    \n",
    "print(\"Time: \" + str(time.time() - start_time))\n",
    "print(\"Mean mse: \" + str(statistics.mean(mse_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8028\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.7992\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.7984\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8015\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8013\n",
      "Mean mse: 0.8006542850284819\n",
      "Time: 421.7394802570343\n"
     ]
    }
   ],
   "source": [
    "mse_results = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for (train_data, test_data) in rating_datasets:\n",
    "    algo = KNNWithMeans(100, 1, {'name': 'cosine', 'user_based': False})\n",
    "\n",
    "    algo.fit(train_data)\n",
    "    predictions = algo.test(test_data)  \n",
    "\n",
    "    mse = accuracy.mse(predictions)\n",
    "    mse_results.append(mse)\n",
    "\n",
    "print(\"Mean mse: \" + str(statistics.mean(mse_results)))\n",
    "print(\"Time: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based approach (SVD, KNNBasic, CoClustering, KNNBaseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<surprise.prediction_algorithms.matrix_factorization.SVD object at 0x000002392418A100>\n",
      "MSE: 0.7648\n",
      "MSE: 0.7642\n",
      "MSE: 0.7602\n",
      "MSE: 0.7633\n",
      "MSE: 0.7650\n",
      "Mean mse: 0.7634908023011225\n",
      "Time: 171.219402551651\n",
      "-----------------------------------------------------\n",
      "<surprise.prediction_algorithms.knns.KNNBasic object at 0x000002392418A1F0>\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8525\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8504\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8497\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8510\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8525\n",
      "Mean mse: 0.8073498960275686\n",
      "Time: 1221.5136618614197\n",
      "-----------------------------------------------------\n",
      "<surprise.prediction_algorithms.co_clustering.CoClustering object at 0x000002392418A130>\n",
      "MSE: 0.8382\n",
      "MSE: 0.8414\n",
      "MSE: 0.8356\n",
      "MSE: 0.8392\n",
      "MSE: 0.8375\n",
      "Mean mse: 0.8176946133573035\n",
      "Time: 1317.121001958847\n",
      "-----------------------------------------------------\n",
      "<surprise.prediction_algorithms.knns.KNNBaseline object at 0x000002392418A160>\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8032\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8003\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.7991\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8022\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8023\n",
      "Mean mse: 0.8136261065432562\n",
      "Time: 1957.7697014808655\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mse_results = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for algorithm in [SVD(random_state=1524401), KNNBasic(random_state=1524401), CoClustering(random_state=1524401), KNNBaseline(random_state=1524401)]:\n",
    "\n",
    "    print(str(algorithm))\n",
    "\n",
    "    for (train_data, test_data) in rating_datasets:\n",
    "        algo = algorithm\n",
    "\n",
    "        algo.fit(train_data)\n",
    "        predictions = algo.test(test_data)\n",
    "\n",
    "        mse = accuracy.mse(predictions)\n",
    "        mse_results.append(mse)\n",
    "        \n",
    "    print(\"Mean mse: \" + str(statistics.mean(mse_results)))\n",
    "    print(\"Time: \" + str(time.time() - start_time))\n",
    "\n",
    "    print(\"-----------------------------------------------------\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "collaborative_filtering_movielense.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
